{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import spacy \r\n",
    "import json \r\n",
    "import random \r\n",
    "\r\n",
    "def load_data(file):\r\n",
    "    \"\"\"\r\n",
    "    takes json file location and \r\n",
    "    returns python object representation of that json file \r\n",
    "    \"\"\"\r\n",
    "    with open(file,\"r\", encoding='utf-8') as f: \r\n",
    "        data = json.load(f) \r\n",
    "    return data \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def save_data(file, data): \r\n",
    "    with open(file,\"w\", encoding='utf-8') as f: \r\n",
    "        json.dump(data,f, indent=4)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "TRAIN_DATA = load_data('hp_training_data.json') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def train_spacy(data, iterations): \r\n",
    "    \"\"\"\r\n",
    "    iterations: epochs on the training dataset \r\n",
    "    \"\"\"\r\n",
    "    TRAIN_DATA = data \r\n",
    "    nlp = spacy.blank('en')\r\n",
    "    if \"ner\" not in nlp.pipe_names: \r\n",
    "        ner = nlp.create_pipe(\"ner\") \r\n",
    "        nlp.add_pipe(ner, last=True) \r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "TRAIN_DATA = load_data('hp_training_data.json') \r\n",
    "iterations = 30\r\n",
    "TRAIN_DATA2 = []\r\n",
    "for val in TRAIN_DATA:\r\n",
    "    if val:\r\n",
    "        TRAIN_DATA2.append(val)\r\n",
    "nlp = spacy.blank('en')\r\n",
    "\r\n",
    "if \"ner\" not in nlp.pipe_names: \r\n",
    "    #ner = nlp.create_pipe(\"ner\") \r\n",
    "    ner = nlp.add_pipe('ner', last=True) \r\n",
    "\r\n",
    "for a, annotations in TRAIN_DATA2: \r\n",
    "    for ent in annotations.get('entities'): \r\n",
    "        ner.add_label(ent[2])\r\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\r\n",
    "if len(other_pipes) == 0:\r\n",
    "    optimizer = nlp.begin_training()\r\n",
    "    for itn in tqdm(range(iterations)):\r\n",
    "        print('starting iteration' + str(itn)) \r\n",
    "        random.shuffle(TRAIN_DATA2)\r\n",
    "        losses = {}\r\n",
    "        from spacy.training.example import Example\r\n",
    "\r\n",
    "        for batch in spacy.util.minibatch(TRAIN_DATA2, size=50):\r\n",
    "            for text, annotations in batch:\r\n",
    "                # create Example\r\n",
    "                doc = nlp.make_doc(text)\r\n",
    "                example = Example.from_dict(doc, annotations)\r\n",
    "                # Update the model\r\n",
    "                nlp.update([example], losses=losses, drop=0.3, sgd = optimizer)\r\n",
    "nlp\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#from spacy.training.example import Example\r\n",
    "\r\n",
    "#for batch in spacy.util.minibatch(TRAIN_DATA2, size=2):\r\n",
    "#    for text, annotations in batch:\r\n",
    "#        # create Example\r\n",
    "#        doc = nlp.make_doc(text)\r\n",
    "#        example = Example.from_dict(doc, annotations)\r\n",
    "#        # Update the model\r\n",
    "#        nlp.update([example], losses=losses, drop=0.3, sgd = optimizer)\r\n",
    "\r\n",
    "#nlp.pipe_names"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1383c6744e1b466793e105808d7c80a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting iteration0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-69370ea46472>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;31m# Update the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 ):\n\u001b[1;32m-> 1131\u001b[1;33m                     \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mannotates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m                 for doc, eg in zip(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.finish_update\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36mfinish_update\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                     param, grad = optimizer(\n\u001b[0m\u001b[0;32m    328\u001b[0m                         \u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\optimizers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, key, weights, gradient, lr_scale)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL2\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL2_is_weight_decay\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[0mweights\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlr_scale\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverages\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "ner.labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART')"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4829509429bc936f3154465d610ee2a3576f51308e11c88f126dfe38dafbbc67"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}