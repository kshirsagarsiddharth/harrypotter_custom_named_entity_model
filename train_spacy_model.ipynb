{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import spacy \r\n",
    "import json \r\n",
    "import random \r\n",
    "\r\n",
    "def load_data(file):\r\n",
    "    \"\"\"\r\n",
    "    takes json file location and \r\n",
    "    returns python object representation of that json file \r\n",
    "    \"\"\"\r\n",
    "    with open(file,\"r\", encoding='utf-8') as f: \r\n",
    "        data = json.load(f) \r\n",
    "    return data \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def save_data(file, data): \r\n",
    "    with open(file,\"w\", encoding='utf-8') as f: \r\n",
    "        json.dump(data,f, indent=4)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "TRAIN_DATA = load_data('hp_training_data.json') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def train_spacy(data, iterations): \r\n",
    "    \"\"\"\r\n",
    "    iterations: epochs on the training dataset \r\n",
    "    \"\"\"\r\n",
    "    TRAIN_DATA = data \r\n",
    "    nlp = spacy.blank('en')\r\n",
    "    if \"ner\" not in nlp.pipe_names: \r\n",
    "        ner = nlp.create_pipe(\"ner\") \r\n",
    "        nlp.add_pipe(ner, last=True) \r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "TRAIN_DATA = load_data('hp_training_data.json') \r\n",
    "iterations = 30\r\n",
    "TRAIN_DATA2 = []\r\n",
    "for val in TRAIN_DATA:\r\n",
    "    if val:\r\n",
    "        TRAIN_DATA2.append(val)\r\n",
    "nlp = spacy.blank('en')\r\n",
    "\r\n",
    "if \"ner\" not in nlp.pipe_names: \r\n",
    "    #ner = nlp.create_pipe(\"ner\") \r\n",
    "    ner = nlp.add_pipe('ner', last=True) \r\n",
    "\r\n",
    "for a, annotations in TRAIN_DATA2: \r\n",
    "    for ent in annotations.get('entities'): \r\n",
    "        ner.add_label(ent[2])\r\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\r\n",
    "if len(other_pipes) == 0:\r\n",
    "    optimizer = nlp.begin_training()\r\n",
    "    for itn in tqdm(range(iterations)):\r\n",
    "        print('starting iteration' + str(itn)) \r\n",
    "        random.shuffle(TRAIN_DATA2)\r\n",
    "        losses = {}\r\n",
    "        from spacy.training.example import Example\r\n",
    "\r\n",
    "        for batch in spacy.util.minibatch(TRAIN_DATA2, size=50):\r\n",
    "            for text, annotations in batch:\r\n",
    "                # create Example\r\n",
    "                doc = nlp.make_doc(text)\r\n",
    "                example = Example.from_dict(doc, annotations)\r\n",
    "                # Update the model\r\n",
    "                nlp.update([example], losses=losses, drop=0.3, sgd = optimizer)\r\n",
    "nlp\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#from spacy.training.example import Example\r\n",
    "\r\n",
    "#for batch in spacy.util.minibatch(TRAIN_DATA2, size=2):\r\n",
    "#    for text, annotations in batch:\r\n",
    "#        # create Example\r\n",
    "#        doc = nlp.make_doc(text)\r\n",
    "#        example = Example.from_dict(doc, annotations)\r\n",
    "#        # Update the model\r\n",
    "#        nlp.update([example], losses=losses, drop=0.3, sgd = optimizer)\r\n",
    "\r\n",
    "#nlp.pipe_names"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b0f5d588e8e4d8789fa47328e4121da"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting iteration0\n",
      "starting iteration1\n",
      "starting iteration2\n",
      "starting iteration3\n",
      "starting iteration4\n",
      "starting iteration5\n",
      "starting iteration6\n",
      "starting iteration7\n",
      "starting iteration8\n",
      "starting iteration9\n",
      "starting iteration10\n",
      "starting iteration11\n",
      "starting iteration12\n",
      "starting iteration13\n",
      "starting iteration14\n",
      "starting iteration15\n",
      "starting iteration16\n",
      "starting iteration17\n",
      "starting iteration18\n",
      "starting iteration19\n",
      "starting iteration20\n",
      "starting iteration21\n",
      "starting iteration22\n",
      "starting iteration23\n",
      "starting iteration24\n",
      "starting iteration25\n",
      "starting iteration26\n",
      "starting iteration27\n",
      "starting iteration28\n",
      "starting iteration29\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x17d19e85790>"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "nlp.to_disk('hp_ner_model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "def train_spacy(data, iterations):\r\n",
    "    from tqdm.notebook import tqdm \r\n",
    "    import random\r\n",
    "    TRAIN_DATA = data \r\n",
    "    TRAIN_DATA2 = []\r\n",
    "    for val  in TRAIN_DATA:\r\n",
    "        if val:\r\n",
    "            TRAIN_DATA2.append(val)\r\n",
    "    \r\n",
    "    nlp = spacy.blank('en')\r\n",
    "    if \"ner\" not in nlp.pipe_names:\r\n",
    "        ner = nlp.add_pipe('ner', last=True) \r\n",
    "    \r\n",
    "    for _, annotations in TRAIN_DATA2:\r\n",
    "        for ent in annotations.get('entities'):\r\n",
    "            ner.add_label(ent[2]) \r\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner'] \r\n",
    "    if len(other_pipes) == 0:\r\n",
    "        optimizer = nlp.begin_training() \r\n",
    "        for itn in tqdm(range(iterations)):\r\n",
    "            print('starting iteration:' + str(itn))\r\n",
    "            random.shuffle(TRAIN_DATA2)\r\n",
    "            losses = {} \r\n",
    "            from spacy.training.example import Example \r\n",
    "\r\n",
    "            for batch in spacy.util.minibatch(TRAIN_DATA2, size = 256):\r\n",
    "                for text, annotations in batch: \r\n",
    "                    doc = nlp.make_doc(text)\r\n",
    "                    example = Example.from_dict(doc, annotations)\r\n",
    "                    nlp.update([example], losses=losses, drop = 0.3, sgd = optimizer)\r\n",
    "    return nlp "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4829509429bc936f3154465d610ee2a3576f51308e11c88f126dfe38dafbbc67"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}