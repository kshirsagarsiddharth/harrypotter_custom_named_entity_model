{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import spacy \r\n",
    "import json \r\n",
    "import random \r\n",
    "\r\n",
    "def load_data(file):\r\n",
    "    \"\"\"\r\n",
    "    takes json file location and \r\n",
    "    returns python object representation of that json file \r\n",
    "    \"\"\"\r\n",
    "    with open(file,\"r\", encoding='utf-8') as f: \r\n",
    "        data = json.load(f) \r\n",
    "    return data \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def save_data(file, data): \r\n",
    "    with open(file,\"w\", encoding='utf-8') as f: \r\n",
    "        json.dump(data,f, indent=4)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "TRAIN_DATA = load_data('hp_training_data.json') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def train_spacy(data, iterations): \r\n",
    "    \"\"\"\r\n",
    "    iterations: epochs on the training dataset \r\n",
    "    \"\"\"\r\n",
    "    TRAIN_DATA = data \r\n",
    "    nlp = spacy.blank('en')\r\n",
    "    if \"ner\" not in nlp.pipe_names: \r\n",
    "        ner = nlp.create_pipe(\"ner\") \r\n",
    "        nlp.add_pipe(ner, last=True) \r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "TRAIN_DATA = load_data('hp_training_data.json') \r\n",
    "iterations = 30\r\n",
    "TRAIN_DATA2 = []\r\n",
    "for val in TRAIN_DATA:\r\n",
    "    if val:\r\n",
    "        TRAIN_DATA2.append(val)\r\n",
    "nlp = spacy.blank('en')\r\n",
    "\r\n",
    "if \"ner\" not in nlp.pipe_names: \r\n",
    "    #ner = nlp.create_pipe(\"ner\") \r\n",
    "    ner = nlp.add_pipe('ner', last=True) \r\n",
    "\r\n",
    "for a, annotations in TRAIN_DATA2: \r\n",
    "    for ent in annotations.get('entities'): \r\n",
    "        ner.add_label(ent[2])\r\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\r\n",
    "if len(other_pipes) == 0:\r\n",
    "    optimizer = nlp.begin_training()\r\n",
    "    for itn in tqdm(range(iterations)):\r\n",
    "        print('starting iteration' + str(itn)) \r\n",
    "        random.shuffle(TRAIN_DATA2)\r\n",
    "        losses = {}\r\n",
    "        from spacy.training.example import Example\r\n",
    "\r\n",
    "        for batch in spacy.util.minibatch(TRAIN_DATA2, size=50):\r\n",
    "            for text, annotations in batch:\r\n",
    "                # create Example\r\n",
    "                doc = nlp.make_doc(text)\r\n",
    "                example = Example.from_dict(doc, annotations)\r\n",
    "                # Update the model\r\n",
    "                nlp.update([example], losses=losses, drop=0.3, sgd = optimizer)\r\n",
    "nlp\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#from spacy.training.example import Example\r\n",
    "\r\n",
    "#for batch in spacy.util.minibatch(TRAIN_DATA2, size=2):\r\n",
    "#    for text, annotations in batch:\r\n",
    "#        # create Example\r\n",
    "#        doc = nlp.make_doc(text)\r\n",
    "#        example = Example.from_dict(doc, annotations)\r\n",
    "#        # Update the model\r\n",
    "#        nlp.update([example], losses=losses, drop=0.3, sgd = optimizer)\r\n",
    "\r\n",
    "#nlp.pipe_names"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b0f5d588e8e4d8789fa47328e4121da"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting iteration0\n",
      "starting iteration1\n",
      "starting iteration2\n",
      "starting iteration3\n",
      "starting iteration4\n",
      "starting iteration5\n",
      "starting iteration6\n",
      "starting iteration7\n",
      "starting iteration8\n",
      "starting iteration9\n",
      "starting iteration10\n",
      "starting iteration11\n",
      "starting iteration12\n",
      "starting iteration13\n",
      "starting iteration14\n",
      "starting iteration15\n",
      "starting iteration16\n",
      "starting iteration17\n",
      "starting iteration18\n",
      "starting iteration19\n",
      "starting iteration20\n",
      "starting iteration21\n",
      "starting iteration22\n",
      "starting iteration23\n",
      "starting iteration24\n",
      "starting iteration25\n",
      "starting iteration26\n",
      "starting iteration27\n",
      "starting iteration28\n",
      "starting iteration29\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x17d19e85790>"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "nlp.to_disk('hp_ner_model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "def train_spacy(data, iterations):\r\n",
    "    from tqdm.notebook import tqdm \r\n",
    "    import random\r\n",
    "    TRAIN_DATA = data \r\n",
    "    TRAIN_DATA2 = []\r\n",
    "    for val  in TRAIN_DATA:\r\n",
    "        if val:\r\n",
    "            TRAIN_DATA2.append(val)\r\n",
    "    \r\n",
    "    nlp = spacy.blank('en')\r\n",
    "    if \"ner\" not in nlp.pipe_names:\r\n",
    "        ner = nlp.add_pipe('ner', last=True) \r\n",
    "    \r\n",
    "    for _, annotations in TRAIN_DATA2:\r\n",
    "        for ent in annotations.get('entities'):\r\n",
    "            ner.add_label(ent[2]) \r\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner'] \r\n",
    "    if len(other_pipes) == 0:\r\n",
    "        optimizer = nlp.begin_training() \r\n",
    "        for itn in tqdm(range(iterations)):\r\n",
    "            print('starting iteration:' + str(itn))\r\n",
    "            random.shuffle(TRAIN_DATA2)\r\n",
    "            losses = {} \r\n",
    "            from spacy.training.example import Example \r\n",
    "\r\n",
    "            for batch in spacy.util.minibatch(TRAIN_DATA2, size = 256):\r\n",
    "                for text, annotations in batch: \r\n",
    "                    doc = nlp.make_doc(text)\r\n",
    "                    example = Example.from_dict(doc, annotations)\r\n",
    "                    nlp.update([example], losses=losses, drop = 0.3, sgd = optimizer)\r\n",
    "    return nlp "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "test = \"\"\"Hermione first met Harry Potter and Ron Weasley aboard the Hogwarts Express, who found her unfriendly and somewhat of an \"insufferable know-it-all\", an impression reinforced by her constant correct answers and eagerness to please the professors. However, she stepped in to take the blame from the boys after they had saved her from a troll on Hallowe'en in 1991, surprising them in a grateful way, which led to them quickly becoming friends. She later played a crucial role in protecting the Philosopher's Stone from Voldemort.\r\n",
    "\r\n",
    "In her second year, Hermione had a key role in the discovery of the Chamber of Secrets, before falling victim to the basilisk unleashed upon Hogwarts following the opening of the Chamber. However, she recovered from the petrification under the care of Madam Pomfrey with Professor Sprout's Mandrake Restorative Draught.\r\n",
    "\r\n",
    "The next year, Hermione was granted permission to use a Time-Turner from the Ministry of Magic to facilitate her volition to study far more subjects than were possible without time travel, though she and Harry later used it to rescue Sirius Black from the Dementor's Kiss and Buckbeak the hippogriff from execution.\r\n",
    "\r\n",
    "During her fourth year, Hermione became an advocate for the better treatment of house-elves, forming the association S.P.E.W., and helped in Harry's preparation for the Triwizard Tournament.\r\n",
    "\r\n",
    "In her fifth year, Hermione was the driving force behind the creation of Dumbledore's Army and fought alongside fellow D.A. members in the Battle of the Department of Mysteries.\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "nlp = spacy.load('hp_ner_model')\r\n",
    "doc = nlp(test)\r\n",
    "for ent in doc.ents:\r\n",
    "    print(ent.text, ent.label_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Harry Potter PERSON\n",
      "Ron Weasley PERSON\n",
      "the Hogwarts Express ORG\n",
      "1991 DATE\n",
      "the Philosopher's Stone ORG\n",
      "Hogwarts ORG\n",
      "Chamber DATE\n",
      "Madam Pomfrey PERSON\n",
      "Sprout's Mandrake Restorative Draught PERSON\n",
      "The next year DATE\n",
      "Time-Turner ORG\n",
      "the Ministry of Magic ORG\n",
      "Harry later used PERSON\n",
      "Sirius Black ORG\n",
      "the Dementor's Kiss and Buckbeak the ORG\n",
      "During PERSON\n",
      "fourth year DATE\n",
      "S.P.E.W. GPE\n",
      "Harry PERSON\n",
      "Triwizard ORG\n",
      "fifth year DATE\n",
      "Dumbledore's Army ORG\n",
      "Mysteries GPE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import re \r\n",
    "def clean_text(text):\r\n",
    "    cleaned = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", text)\r\n",
    "    return cleaned"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "test = clean_text(test)\r\n",
    "nlp = spacy.load('hp_ner_model')\r\n",
    "doc = nlp(test)\r\n",
    "for ent in doc.ents:\r\n",
    "    print(ent.text, ent.label_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Harry Potter PERSON\n",
      "Ron Weasley PERSON\n",
      "the Hogwarts Express ORG\n",
      "1991 DATE\n",
      "the Philosopher's Stone ORG\n",
      "Hogwarts ORG\n",
      "Chamber DATE\n",
      "Madam Pomfrey PERSON\n",
      "Sprout's Mandrake Restorative Draught PERSON\n",
      "The next year DATE\n",
      "Time-Turner ORG\n",
      "the Ministry of Magic ORG\n",
      "Harry later used PERSON\n",
      "Sirius Black ORG\n",
      "the Dementor's Kiss and Buckbeak the ORG\n",
      "During PERSON\n",
      "fourth year DATE\n",
      "S.P.E.W. GPE\n",
      "Harry PERSON\n",
      "Triwizard ORG\n",
      "fifth year DATE\n",
      "Dumbledore's Army ORG\n",
      "Mysteries GPE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4829509429bc936f3154465d610ee2a3576f51308e11c88f126dfe38dafbbc67"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}