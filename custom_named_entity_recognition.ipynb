{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import json \r\n",
    "import spacy \r\n",
    "from spacy.lang.en import English \r\n",
    "from spacy.pipeline import EntityRuler # allows to create rules \r\n",
    "from spacy.language import Language"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def load_data(file):\r\n",
    "    \"\"\"\r\n",
    "    takes json file location and python representation of that json file \r\n",
    "    \"\"\"\r\n",
    "    with open(file,\"r\", encoding='utf-8') as f: \r\n",
    "        data = json.load(f) \r\n",
    "    return data "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "def generate_better_characters(file):\r\n",
    "    \"\"\"\r\n",
    "    This function cleanes and generates all the possible \r\n",
    "    combinations of the names. \r\n",
    "    \"\"\"\r\n",
    "    data = load_data(file) \r\n",
    "    #print(len(data))\r\n",
    "    new_characters = []\r\n",
    "    for item in data:\r\n",
    "        new_characters.append(item)\r\n",
    "\r\n",
    "    for item in data: \r\n",
    "        item = item.replace(\"The\",\"\").replace(\"the\",\"\").replace(\"and\",\"\").replace(\"And\",\"\") \r\n",
    "        names = item.split(\" \")\r\n",
    "        for name in names:\r\n",
    "            name = name.strip() \r\n",
    "            new_characters.append(name)\r\n",
    "        \r\n",
    "        if \"(\" in item:\r\n",
    "            names = item.split(\"(\")\r\n",
    "            for name in names:\r\n",
    "                name = name.replace(\")\",\"\").strip()\r\n",
    "                new_characters.append(name)\r\n",
    "\r\n",
    "        if \",\" in item:\r\n",
    "            names = item.split(\",\")\r\n",
    "            for name in names:\r\n",
    "                if \" \" in name:\r\n",
    "                    new_names = name.split()\r\n",
    "                    for new_name in new_names:\r\n",
    "                        new_characters.append(new_name.strip())\r\n",
    "                        #print(new_name)\r\n",
    "                new_characters.append(name.replace(\"and\",\"\").strip())\r\n",
    "    \r\n",
    "    final_characters = []\r\n",
    "    titles = [\"Dr.\",\"Professor\",\"Mr.\",\"Mrs.\",\"Ms.\",\"Miss\",\"Aunt\",\"Uncle\",\"Mr. and Mrs.\"] \r\n",
    "    for character in new_characters: \r\n",
    "        if \"\" != character:\r\n",
    "            final_characters.append(character) \r\n",
    "            for title in titles: \r\n",
    "                titled_char = f\"{title} {character}\"\r\n",
    "                #print(titled_char)\r\n",
    "                final_characters.append(titled_char) \r\n",
    "    #print(len(final_characters))\r\n",
    "\r\n",
    "    final_characters = list(set(final_characters))\r\n",
    "    final_characters = sorted(final_characters)\r\n",
    "    #print(len(final_characters))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "                \r\n",
    "            \r\n",
    "    return final_characters"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "\r\n",
    "def create_training_data(file, type): \r\n",
    "    data = generate_better_characters(file) \r\n",
    "    patterns = [] \r\n",
    "    for item in data: \r\n",
    "        pattern = {\r\n",
    "            'label':type,\r\n",
    "            'pattern':item\r\n",
    "        }\r\n",
    "        patterns.append(pattern)\r\n",
    "    return patterns\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "\r\n",
    "def generate_rules(patterns):\r\n",
    "    nlp = English()\r\n",
    "    source_nlp = spacy.load(\"en_core_web_sm\")\r\n",
    "    nlp.add_pipe(\"ner\", source=source_nlp)\r\n",
    "    ruler = EntityRuler(nlp)\r\n",
    "    ruler.add_patterns(patterns)\r\n",
    "    nlp.to_disk(\"hp_ner\")\r\n",
    "\r\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "patterns = create_training_data('hp_characters.json','PERSON')\r\n",
    "generate_rules(patterns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "def test_model(nlp, text): \r\n",
    "    \r\n",
    "    doc = nlp(text) \r\n",
    "    results = [] \r\n",
    "    for ent in doc.ents:\r\n",
    "        results.append(ent.text)\r\n",
    "    return results \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "nlp = spacy.load(\"hp_ner\")\r\n",
    "ie_data = {}\r\n",
    "with open('hp.txt','r', encoding = 'utf-8') as f: \r\n",
    "    text = f.read()\r\n",
    "    chapters = text.split('CHAPTER')[1:] \r\n",
    "    for chapter in chapters: \r\n",
    "        chapter_num, chapter_title = chapter.split(\"\\n\\n\")[:2]\r\n",
    "        chapter_num = chapter_num.strip()\r\n",
    "        chapter_title = chapter_title.strip()\r\n",
    "        segments = chapter.split('\\n\\n')[2:]\r\n",
    "        hits = [] \r\n",
    "        for segment in segments:\r\n",
    "            segment = segment.strip() \r\n",
    "            segment = segment.replace(\"\\n\",\"\") \r\n",
    "            results = test_model(nlp, segment)\r\n",
    "            for result in results: \r\n",
    "                hits.append(result)\r\n",
    "        ie_data[chapter_num] = hits \r\n",
    "            \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4829509429bc936f3154465d610ee2a3576f51308e11c88f126dfe38dafbbc67"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}